{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d70db8-f7ae-47bb-9998-b50e08d2ab85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computation of TF-Glycogene interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b4cd7-c21c-40be-ad59-cc5d878842e5",
   "metadata": {},
   "source": [
    "#### Prepare single-cell gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5d4aea-07cb-47d2-9bee-c67765c62977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Load libraries\n",
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#%% Define directory locations (Change according to folder structure preferred)\n",
    "mainDir = '/Users/rudi/Data/TS_Codes/TF/' \n",
    "dataDir = '/Users/rudi/Data/TS_Codes/data/'\n",
    "processedDir = ''.join([dataDir, 'processed/'])\n",
    "figDir = ''.join([mainDir, 'figures/'])\n",
    "sc.settings.figdir = figDir\n",
    "\n",
    "os.chdir(mainDir)\n",
    "\n",
    "#%% Set scanpy parameters\n",
    "sc.set_figure_params(dpi=100, color_map = 'viridis_r')\n",
    "sc.settings.n_jobs=2\n",
    "sc.settings.verbosity = 1\n",
    "sns.set_style(\"ticks\", {'axes.grid' : False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5f04c4-d71f-4ac6-86ee-b8b32feb01a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% Load Tabula data \n",
    "tabula_file = ''.join([processedDir, 'TS_norm_log1p.h5ad'])\n",
    "tabula = sc.read_h5ad(tabula_file)\n",
    "\n",
    "#%% Get decontaminated counts\n",
    "tabula.X = tabula.layers['decontXcounts'].copy()\n",
    "\n",
    "#%% Get scaled UMI counts\n",
    "sc.pp.normalize_total(tabula, target_sum=1e4) # Normalize counts such that each cell has a total of 1e4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53ed3c6-286b-45e2-a887-8ba17533c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of genes found in dataset are:\n",
      "protein_coding                        19847\n",
      "lncRNA                                14936\n",
      "processed_pseudogene                  10114\n",
      "unprocessed_pseudogene                 2567\n",
      "misc_RNA                               2210\n",
      "snRNA                                  1901\n",
      "miRNA                                  1875\n",
      "TEC                                    1048\n",
      "snoRNA                                  941\n",
      "transcribed_unprocessed_pseudogene      940\n",
      "transcribed_processed_pseudogene        506\n",
      "rRNA_pseudogene                         494\n",
      "IG_V_pseudogene                         187\n",
      "transcribed_unitary_pseudogene          150\n",
      "IG_V_gene                               145\n",
      "TR_V_gene                               106\n",
      "unitary_pseudogene                       96\n",
      "TR_J_gene                                79\n",
      "scaRNA                                   49\n",
      "rRNA                                     47\n",
      "IG_D_gene                                37\n",
      "TR_V_pseudogene                          33\n",
      "Mt_tRNA                                  22\n",
      "artifact                                 19\n",
      "IG_J_gene                                18\n",
      "pseudogene                               15\n",
      "IG_C_gene                                14\n",
      "IG_C_pseudogene                           9\n",
      "ribozyme                                  8\n",
      "TR_C_gene                                 6\n",
      "sRNA                                      5\n",
      "TR_D_gene                                 4\n",
      "TR_J_pseudogene                           4\n",
      "translated_unprocessed_pseudogene         3\n",
      "IG_J_pseudogene                           3\n",
      "translated_processed_pseudogene           2\n",
      "Mt_rRNA                                   2\n",
      "vault_RNA                                 1\n",
      "scRNA                                     1\n",
      "IG_pseudogene                             1\n",
      "Name: gene_biotype, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#%% Scripts for subsetting data\n",
    "\n",
    "# Subset data based on sequencing technology(10X or Smart-Seq) \n",
    "tabula = tabula[tabula.obs['assay']=='10x 3\\' v3'] #Use for 10X\n",
    "\n",
    "#%% Subset data to specific genes (in this case protein-coding transcripts only)\n",
    "genes_found = pd.read_csv(''.join([dataDir, 'Tabulagenes_ensemblmetadata.csv'])) # BioMart mapping of genes\n",
    "types_of_genes = genes_found['gene_biotype'] #Gene biotype has info on which type of RNA each ensembl id is mapped to\n",
    "\n",
    "# Display the counts of different transcript types\n",
    "print('The types of genes found in dataset are:')\n",
    "print(types_of_genes.value_counts())\n",
    "\n",
    "# Merge ensembl id mapping with Tabula variables\n",
    "tabula.var = (tabula.var.reset_index().\n",
    "              merge(genes_found, how = 'left', left_on = 'gene_id', right_on = 'ensembl_gene_id').\n",
    "              set_index('gene_id')) #Merge the info of mapping to adata object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465c3305-d8fc-4b5f-b65a-14a17fcc8c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glycogenes missing in dataset are:\n",
      "{'GALNT19', 'UGT1A5', 'UGT1A3'}\n"
     ]
    }
   ],
   "source": [
    "#%% Load GlycoEnzOnto gene sets and subset data to glycogenes\n",
    "glycoOntoDir = ''.join([dataDir, 'GlycoEnzOnto/'])\n",
    "GlycoEnzOntoFile = ''.join([glycoOntoDir, 'GlycoEnzOntoEns.json'])# Ensembl IDs of all glycogenes\n",
    "with open(GlycoEnzOntoFile, 'r') as json_file:\n",
    "    glycoSet = json.load(json_file)\n",
    "\n",
    "GlycoEnzOntoFile = ''.join([glycoOntoDir, 'GlycoEnzOnto.json'])# Gene symbols of all glycogenes\n",
    "with open(GlycoEnzOntoFile, 'r') as json_file:\n",
    "    glycoSetnames = json.load(json_file)\n",
    "\n",
    "# Filter glyco gene sets to gene symbols in data\n",
    "glycoSetnames_filter = {k: list({e for i, e in enumerate(v) if e in tabula.var['feature_name'].tolist()}) \n",
    "            for k, v in glycoSetnames.items()}\n",
    "\n",
    "# Filter glyco gene sets to ensembleID in data\n",
    "glycoSet_filter = {k: list({e for i, e in enumerate(v) if e in tabula.var.index.tolist()}) \n",
    "            for k, v in glycoSet.items()}\n",
    "\n",
    "# Get merged list of glycogenes detected in dataset and remove duplicates\n",
    "glycoGeneNames = list({e for k, v in glycoSetnames_filter.items() for i, e in enumerate(v)}) \n",
    "glycoGenes = list({e for k, v in glycoSet_filter.items() for i, e in enumerate(v)})\n",
    "\n",
    "# Check missing glycogenes in dataset\n",
    "glycoGeneNames_notfound ={e for k, v in glycoSetnames.items() for i, e in enumerate(v)} - set(tabula.var['feature_name'].tolist())\n",
    "glycoGenes_notfound ={e for k, v in glycoSet.items() for i, e in enumerate(v)} - set(tabula.var.index.tolist())\n",
    "\n",
    "print('Glycogenes missing in dataset are:')\n",
    "print(glycoGeneNames_notfound)\n",
    "\n",
    "#Add additional column to data.var to indicate if genes are glycogenes\n",
    "tabula.var['isglyco'] = tabula.var['feature_name'].isin(glycoGeneNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ba03b1-2345-46db-b6ca-8b20dbf75b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load TF set\n",
    "tf_file = ''.join([dataDir,'tf_set.pkl'])\n",
    "\n",
    "with open(tf_file, 'rb') as f:\n",
    "    tf_set = pickle.load(f)\n",
    "\n",
    "#Add additional column to data.var to indicate if genes are TFs\n",
    "tabula.var['isTF'] = tabula.var['feature_name'].isin(tf_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4731ec56-2fd9-40c0-9f52-79c705fcc6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subset to TFs and Glycogenes\n",
    "tabula = tabula[:, (tabula.var['isglyco'] == True) | (tabula.var['isTF'] == True)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce62858-a06f-42c6-befe-4f8cc512a260",
   "metadata": {},
   "source": [
    "#### Computation of mutual information between TF and glycogene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a4a1ce4-ef8f-4922-acd0-be36671aed17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parallel calculation for MI\n",
    "import csv\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from mi_computation import compute_mi\n",
    "\n",
    "# Define the path for the output file\n",
    "output_file_path = ''.join([mainDir, 'mi_results.txt'])\n",
    "\n",
    "# Convert the expression matrix to a dense format if it's stored as a sparse matrix\n",
    "expression = tabula.X.toarray() if scipy.sparse.issparse(tabula.X) else tabula.X\n",
    "\n",
    "# Get the indices of glyco genes and TF genes\n",
    "glycogenes = np.where(tabula.var['isglyco'])[0]\n",
    "tfs = np.where(tabula.var['isTF'])[0]\n",
    "\n",
    "# Use a process pool to parallelize the computation\n",
    "with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    # Prepare the list of tasks\n",
    "    tasks = [(glycogene, tf) for glycogene in glycogenes for tf in tfs]\n",
    "\n",
    "    # Open the output file in append mode\n",
    "    with open(output_file_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "\n",
    "        # Write the header if the file is empty (i.e., we're starting fresh)\n",
    "        if f.tell() == 0:\n",
    "            writer.writerow(['TF', 'Glycogene', 'MI'])\n",
    "\n",
    "        # Submit the tasks to the pool and process completed tasks\n",
    "        future_to_mi = {\n",
    "            executor.submit(compute_mi, expression[:, pair[0]], expression[:, pair[1]]): pair for pair in tasks\n",
    "        }\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_mi):\n",
    "            pair = future_to_mi[future]\n",
    "            try:\n",
    "                mi = future.result()\n",
    "                glycogene_name = tabula.var['feature_name'][pair[0]]\n",
    "                tf_name = tabula.var['feature_name'][pair[1]]\n",
    "\n",
    "                # Write the result for this pair as soon as it's available\n",
    "                writer.writerow([tf_name, glycogene_name, mi])\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (pair, exc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c6687-e21c-41c1-9d27-c81b373a8800",
   "metadata": {},
   "source": [
    "#### Computation of Pearson and Spearman correlations between TF and glycogene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208d2fb-ab09-44d8-8fe4-36bbe54d2831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Parallel calculation for correlations\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from mi_computation import compute_pearson, compute_spearman\n",
    "\n",
    "# Convert the expression matrix to a dense format if it's stored as a sparse matrix\n",
    "expression = tabula.X.toarray() if scipy.sparse.issparse(tabula.X) else tabula.X\n",
    "\n",
    "# Get the indices of glyco genes and TF genes\n",
    "glycogenes = np.where(tabula.var['isglyco'])[0]\n",
    "tfs = np.where(tabula.var['isTF'])[0]\n",
    "\n",
    "# Prepare dictionaries to store the results\n",
    "pearson_results = {}\n",
    "spearman_results = {}\n",
    "\n",
    "# Use a process pool to parallelize the computation\n",
    "with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    # Prepare the list of tasks for each type of computation\n",
    "    tasks = [(glycogene, tf) for glycogene in glycogenes for tf in tfs]\n",
    "    \n",
    "    # Submit the tasks to the pool for Pearson correlation\n",
    "    future_to_pearson = {\n",
    "        executor.submit(compute_pearson, expression[:, pair[0]], expression[:, pair[1]]): pair for pair in tasks\n",
    "    }\n",
    "\n",
    "    # Submit the tasks to the pool for Spearman correlation\n",
    "    future_to_spearman = {\n",
    "        executor.submit(compute_spearman, expression[:, pair[0]], expression[:, pair[1]]): pair for pair in tasks\n",
    "    }\n",
    "    \n",
    "    # Collect the results as they are completed for Pearson\n",
    "    for future in concurrent.futures.as_completed(future_to_pearson):\n",
    "        pair = future_to_pearson[future]\n",
    "        try:\n",
    "            pearson_corr = future.result()\n",
    "            glycogene_name = tabula.var['feature_name'][pair[0]]\n",
    "            tf_name = tabula.var['feature_name'][pair[1]]\n",
    "            pearson_results.setdefault(glycogene_name, {})[tf_name] = pearson_corr\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (pair, exc))\n",
    "\n",
    "    # Collect the results as they are completed for Spearman\n",
    "    for future in concurrent.futures.as_completed(future_to_spearman):\n",
    "        pair = future_to_spearman[future]\n",
    "        try:\n",
    "            spearman_corr = future.result()\n",
    "            glycogene_name = tabula.var['feature_name'][pair[0]]\n",
    "            tf_name = tabula.var['feature_name'][pair[1]]\n",
    "            spearman_results.setdefault(glycogene_name, {})[tf_name] = spearman_corr\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (pair, exc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb68fd24-ec7e-4bb1-a061-cb6253958d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Pearson correlation results\n",
    "pearson_list = []\n",
    "for glycogene, tf_dict in pearson_results.items():\n",
    "    for tf, pearson in tf_dict.items():\n",
    "        pearson_list.append((tf, glycogene, pearson))\n",
    "\n",
    "with open('pearson_results.txt', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['TF', 'Glycogene', 'score'])\n",
    "    writer.writerows(pearson_list)\n",
    "\n",
    "# Save Spearman correlation results\n",
    "spearman_list = []\n",
    "for glycogene, tf_dict in spearman_results.items():\n",
    "    for tf, spearman in tf_dict.items():\n",
    "        spearman_list.append((tf, glycogene, spearman))\n",
    "\n",
    "with open('spearman_results.txt', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['TF', 'Glycogene', 'score'])\n",
    "    writer.writerows(spearman_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caaabc8-918a-4d44-b07c-79b478ca5ea7",
   "metadata": {},
   "source": [
    "#### Assesment of accuracy by AUROC and AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dac23f03-6cc5-46f4-82e9-d559d720bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for MI: 0.6585762928081625\n",
      "AUPR for MI: 0.4447855158386184\n",
      "Fraction of positive cases: 0.3178737331081081\n"
     ]
    }
   ],
   "source": [
    "# Evaluate AUROC and AUPR for MI\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Load the TFLink.tsv file\n",
    "TFfile = ''.join([dataDir,'TFLink.tsv'])\n",
    "TFLink = pd.read_csv(TFfile, delimiter='\\t')\n",
    "TFLink = TFLink[['Name.TF', 'Name.Target']].rename(columns={'Name.TF': 'TF', 'Name.Target': 'Gene'})\n",
    "\n",
    "# Load the mi_results.txt file\n",
    "results = pd.read_csv('mi_results.txt', delimiter='\\t')\n",
    "\n",
    "# Get unique TFs and glycogenes from nmi\n",
    "TFs = results['TF'].unique()\n",
    "glycogenes = results['Glycogene'].unique()\n",
    "\n",
    "# Subset the TFLink DataFrame\n",
    "TFLink = TFLink[(TFLink['TF'].isin(TFs)) & (TFLink['Gene'].isin(glycogenes))]\n",
    "\n",
    "# Merge the nmi DataFrame with the TFLink DataFrame to label each TF-Gene pair\n",
    "results = results.merge(TFLink.assign(link=1), how='left', left_on=['TF', 'Glycogene'], right_on=['TF', 'Gene'])\n",
    "\n",
    "# Fill missing values in the NMI column with 0 and in the link column with 0\n",
    "results['MI'] = results['MI'].fillna(0)\n",
    "results['link'] = results['link'].fillna(0)\n",
    "\n",
    "# Use the NMI scores as the prediction scores and the link column as the true labels\n",
    "scores = results['MI']\n",
    "labels = results['link']\n",
    "\n",
    "# Compute the AUROC\n",
    "auroc = roc_auc_score(labels, scores)\n",
    "print('AUROC for MI:', auroc)\n",
    "\n",
    "# Generate the precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(labels, scores)\n",
    "\n",
    "# Calculate the AUPR\n",
    "aupr = auc(recall, precision)\n",
    "print('AUPR for MI:', aupr)\n",
    "\n",
    "# Calculate the fraction of positive cases in the ground truth\n",
    "num_positive_cases = labels.sum()\n",
    "total_cases = len(labels)\n",
    "fraction_positive = num_positive_cases / total_cases\n",
    "\n",
    "print('Fraction of positive cases:', fraction_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6112b831-2c4e-4c02-b88d-9f6b43498108",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for Pearson corr.: 0.5475275436733957\n",
      "AUPR for Pearson corr.: 0.36724340612588785\n",
      "Fraction of positive cases: 0.3178737331081081\n"
     ]
    }
   ],
   "source": [
    "# Evaluate AUROC and AUPR\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Load the TFLink.tsv file\n",
    "TFfile = ''.join([dataDir,'TFLink.tsv'])\n",
    "TFLink = pd.read_csv(TFfile, delimiter='\\t')\n",
    "TFLink = TFLink[['Name.TF', 'Name.Target']].rename(columns={'Name.TF': 'TF', 'Name.Target': 'Gene'})\n",
    "\n",
    "# Load the mi_results.txt file\n",
    "results = pd.read_csv('pearson_results.txt', delimiter='\\t')\n",
    "\n",
    "# Get unique TFs and glycogenes from nmi\n",
    "TFs = results['TF'].unique()\n",
    "glycogenes = results['Glycogene'].unique()\n",
    "\n",
    "# Subset the TFLink DataFrame\n",
    "TFLink = TFLink[(TFLink['TF'].isin(TFs)) & (TFLink['Gene'].isin(glycogenes))]\n",
    "\n",
    "# Merge the nmi DataFrame with the TFLink DataFrame to label each TF-Gene pair\n",
    "results = results.merge(TFLink.assign(link=1), how='left', left_on=['TF', 'Glycogene'], right_on=['TF', 'Gene'])\n",
    "\n",
    "# Fill missing values in the NMI column with 0 and in the link column with 0\n",
    "results['score'] = results['score'].fillna(0)\n",
    "results['link'] = results['link'].fillna(0)\n",
    "\n",
    "# Use the NMI scores as the prediction scores and the link column as the true labels\n",
    "scores = results['score']\n",
    "labels = results['link']\n",
    "\n",
    "# Compute the AUROC\n",
    "auroc = roc_auc_score(labels, scores)\n",
    "print('AUROC for Pearson corr.:', auroc)\n",
    "\n",
    "# Generate the precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(labels, scores)\n",
    "\n",
    "# Calculate the AUPR\n",
    "aupr = auc(recall, precision)\n",
    "print('AUPR for Pearson corr.:', aupr)\n",
    "\n",
    "# Calculate the fraction of positive cases in the ground truth\n",
    "num_positive_cases = labels.sum()\n",
    "total_cases = len(labels)\n",
    "fraction_positive = num_positive_cases / total_cases\n",
    "\n",
    "print('Fraction of positive cases:', fraction_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c240624-c58c-41dd-a34c-6a83e892c170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for Spearman corr.: 0.6026565985676249\n",
      "AUPR for Spearman corr.: 0.3963190302482294\n",
      "Fraction of positive cases: 0.3178737331081081\n"
     ]
    }
   ],
   "source": [
    "# Evaluate AUROC and AUPR\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Load the TFLink.tsv file\n",
    "TFfile = ''.join([dataDir,'TFLink.tsv'])\n",
    "TFLink = pd.read_csv(TFfile, delimiter='\\t')\n",
    "TFLink = TFLink[['Name.TF', 'Name.Target']].rename(columns={'Name.TF': 'TF', 'Name.Target': 'Gene'})\n",
    "\n",
    "# Load the mi_results.txt file\n",
    "results = pd.read_csv('spearman_results.txt', delimiter='\\t')\n",
    "\n",
    "# Get unique TFs and glycogenes from nmi\n",
    "TFs = results['TF'].unique()\n",
    "glycogenes = results['Glycogene'].unique()\n",
    "\n",
    "# Subset the TFLink DataFrame\n",
    "TFLink = TFLink[(TFLink['TF'].isin(TFs)) & (TFLink['Gene'].isin(glycogenes))]\n",
    "\n",
    "# Merge the nmi DataFrame with the TFLink DataFrame to label each TF-Gene pair\n",
    "results = results.merge(TFLink.assign(link=1), how='left', left_on=['TF', 'Glycogene'], right_on=['TF', 'Gene'])\n",
    "\n",
    "# Fill missing values in the NMI column with 0 and in the link column with 0\n",
    "results['score'] = results['score'].fillna(0)\n",
    "results['link'] = results['link'].fillna(0)\n",
    "\n",
    "# Use the NMI scores as the prediction scores and the link column as the true labels\n",
    "scores = results['score']\n",
    "labels = results['link']\n",
    "\n",
    "# Compute the AUROC\n",
    "auroc = roc_auc_score(labels, scores)\n",
    "print('AUROC for Spearman corr.:', auroc)\n",
    "\n",
    "# Generate the precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(labels, scores)\n",
    "\n",
    "# Calculate the AUPR\n",
    "aupr = auc(recall, precision)\n",
    "print('AUPR for Spearman corr.:', aupr)\n",
    "\n",
    "# Calculate the fraction of positive cases in the ground truth\n",
    "num_positive_cases = labels.sum()\n",
    "total_cases = len(labels)\n",
    "fraction_positive = num_positive_cases / total_cases\n",
    "\n",
    "print('Fraction of positive cases:', fraction_positive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
